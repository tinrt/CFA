{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06c37fd",
   "metadata": {},
   "source": [
    "## CFA Data Exploratory Analysis\n",
    "\n",
    "### 10/28\n",
    "### Tina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "230bbbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13110ef8",
   "metadata": {},
   "source": [
    "Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4007d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8984a1d",
   "metadata": {},
   "source": [
    "Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4bcb2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connected\")\n",
    "except Exception as e:\n",
    "    print(\"Connection failed:\", e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f06c4",
   "metadata": {},
   "source": [
    "Load all public tables into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4017ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded client_visit (1000 rows, 50 columns)\n",
      "Loaded inventory_group (9 rows, 10 columns)\n",
      "Loaded inventory_group_item (17 rows, 8 columns)\n",
      "Loaded inventory_group_location_manifest (0 rows, 8 columns)\n",
      "Loaded inventory_item (716 rows, 31 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\1313306925.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query.as_string(conn), conn)\n",
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\1313306925.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query.as_string(conn), conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded inventory_item_code (158 rows, 9 columns)\n",
      "Loaded inventory_item_location_manifest (1000 rows, 8 columns)\n",
      "Loaded inventory_item_tag (11 rows, 16 columns)\n",
      "Loaded inventory_item_type (26 rows, 12 columns)\n",
      "Loaded inventory_items_inventory_item_tags (116 rows, 2 columns)\n",
      "Loaded inventory_receive (1000 rows, 16 columns)\n",
      "Loaded inventory_receive_group (0 rows, 9 columns)\n",
      "Loaded inventory_receive_item (1000 rows, 14 columns)\n",
      "Loaded inventory_source (239 rows, 21 columns)\n",
      "Loaded location (10 rows, 22 columns)\n",
      "Loaded visit_answer (1000 rows, 15 columns)\n",
      "Loaded visit_budget_item (1000 rows, 9 columns)\n",
      "Loaded visit_item (1000 rows, 18 columns)\n",
      "Loaded visit_member (1000 rows, 18 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\1313306925.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query.as_string(conn), conn)\n"
     ]
    }
   ],
   "source": [
    "tables_dict = {}\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public'\n",
    "    ORDER BY table_name;\n",
    "\"\"\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    query = sql.SQL(\"SELECT * FROM {} LIMIT 1000\").format(sql.Identifier(table_name))\n",
    "    try:\n",
    "        df = pd.read_sql_query(query.as_string(conn), conn)\n",
    "        tables_dict[table_name] = df\n",
    "        print(f\"Loaded {table_name} ({df.shape[0]} rows, {df.shape[1]} columns)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load {table_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb3044",
   "metadata": {},
   "source": [
    "Basic info per table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfe9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: make objects JSON safe\n",
    "# -----------------------------\n",
    "def make_json_safe(obj):\n",
    "    \"\"\"Recursively convert non-JSON-serializable objects.\"\"\"\n",
    "    if isinstance(obj, (datetime, date)):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {str(k): make_json_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_json_safe(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# -----------------------------\n",
    "# Main summary collector\n",
    "# -----------------------------\n",
    "summary = {}\n",
    "\n",
    "for name, df in tables_dict.items():\n",
    "    # --- Data type & cardinality summary ---\n",
    "    dtype_info = df.dtypes.astype(str)\n",
    "    nunique = df.nunique(dropna=True)\n",
    "    dtype_summary = pd.DataFrame({\n",
    "        \"dtype\": dtype_info,\n",
    "        \"unique_values\": nunique,\n",
    "        \"missing_%\": (df.isna().sum() / len(df) * 100).round(2)\n",
    "    }).sort_values(by=\"unique_values\", ascending=False)\n",
    "    \n",
    "    # --- Table-level summary ---\n",
    "    table_summary = {\n",
    "        \"shape\": {\"rows\": int(df.shape[0]), \"columns\": int(df.shape[1])},\n",
    "        \"columns\": list(df.columns),\n",
    "        \"dtype_summary\": make_json_safe(dtype_summary.to_dict(orient=\"index\")),\n",
    "        \"missing_values_percent\": make_json_safe((df.isna().sum() / len(df) * 100).round(2).to_dict()),\n",
    "        \"numeric_summary\": {},\n",
    "        \"categorical_summary\": {}\n",
    "    }\n",
    "\n",
    "    # --- Numeric summary ---\n",
    "    num_cols = df.select_dtypes(include='number').columns\n",
    "    if len(num_cols) > 0:\n",
    "        desc = df[num_cols].describe().T\n",
    "        table_summary[\"numeric_summary\"] = make_json_safe(desc.to_dict())\n",
    "\n",
    "    # --- Categorical summary ---\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        counts = df[col].value_counts().head(5).to_dict()\n",
    "        table_summary[\"categorical_summary\"][col] = make_json_safe(counts)\n",
    "\n",
    "    summary[name] = table_summary\n",
    "\n",
    "    # --- Clean print to console ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TABLE: {name.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\\n\")\n",
    "\n",
    "    print(\"Top Columns by Uniqueness:\")\n",
    "    print(dtype_summary.head(10).to_string())\n",
    "    print(\"\\nMissing Values (%):\")\n",
    "    for col, pct in table_summary[\"missing_values_percent\"].items():\n",
    "        if pct > 0:\n",
    "            print(f\"  {col:<30} {pct:.2f}%\")\n",
    "\n",
    "    print(\"\\nNumeric Columns:\", list(num_cols))\n",
    "    print(\"Categorical Columns:\", list(cat_cols))\n",
    "\n",
    "\n",
    "output_json_path = \"table_summary.json\"\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(make_json_safe(summary), f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88348481",
   "metadata": {},
   "source": [
    "daily activity trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b36f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"daily_activity_trends\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name, df in tables_dict.items():\n",
    "    time_cols = [c for c in df.columns if \"created_at\" in c or \"datetime\" in c]\n",
    "    \n",
    "    for col in time_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        ts = df[col].dropna().dt.date.value_counts().sort_index()\n",
    "\n",
    "        if len(ts) > 0:\n",
    "            # --- Plot ---\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            ts.plot(kind='line', marker='o', linewidth=2, alpha=0.7)\n",
    "            plt.title(f\"Activity Over Time — {name}.{col}\", fontsize=16, fontweight='bold')\n",
    "            plt.xlabel(\"Date\", fontsize=12)\n",
    "            plt.ylabel(\"Number of Records\", fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.5)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # --- Save plot ---\n",
    "            safe_name = f\"{name}_{col}\".replace('.', '_').replace('/', '_')\n",
    "            file_path = os.path.join(output_dir, f\"{safe_name}.png\")\n",
    "            plt.savefig(file_path, dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # --- Create JSON summary ---\n",
    "            summary_data = {\n",
    "                \"table\": name,\n",
    "                \"column\": col,\n",
    "                \"total_records\": int(ts.sum()),\n",
    "                \"unique_days\": int(len(ts)),\n",
    "                \"first_date\": str(ts.index.min()),\n",
    "                \"last_date\": str(ts.index.max()),\n",
    "                \"average_records_per_day\": round(ts.mean(), 2),\n",
    "                \"peak_day\": str(ts.idxmax()),\n",
    "                \"peak_count\": int(ts.max())\n",
    "            }\n",
    "\n",
    "            json_path = os.path.join(output_dir, f\"{safe_name}.json\")\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(summary_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082649ce",
   "metadata": {},
   "source": [
    "categorical charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3b66e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\3747194325.py:21: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\3747194325.py:21: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\3747194325.py:21: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\3747194325.py:21: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\TinTin\\AppData\\Local\\Temp\\ipykernel_2164\\3747194325.py:21: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"categorical_charts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name, df in tables_dict.items():\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    for col in cat_cols:\n",
    "        vc = df[col].value_counts().head(10)\n",
    "\n",
    "        if len(vc) <= 1:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        vc.plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "\n",
    "        plt.title(f\"Top 10 Values — {name}.{col}\", fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.4)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        safe_name = f\"{name}_{col}\".replace('.', '_').replace('/', '_')\n",
    "        file_path = os.path.join(output_dir, f\"{safe_name}.png\")\n",
    "\n",
    "        plt.savefig(file_path, dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715914b",
   "metadata": {},
   "source": [
    "activity trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a275476",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"activity_trends\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name, df in tables_dict.items():\n",
    "    time_cols = [c for c in df.columns if \"created_at\" in c or \"datetime\" in c]\n",
    "\n",
    "    for col in time_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        ts = df[col].dropna().dt.to_period(\"M\").value_counts().sort_index()\n",
    "\n",
    "        if len(ts) > 0:\n",
    "            ts.index = ts.index.to_timestamp()\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            ts.plot(kind='line', marker='o', linewidth=2, alpha=0.7)\n",
    "            plt.title(f\"Monthly Activity Trend — {name}.{col}\", fontsize=16, fontweight=\"bold\")\n",
    "            plt.xlabel(\"Month\", fontsize=12)\n",
    "            plt.ylabel(\"Record Count\", fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.5)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            safe_name = f\"{name}_{col}\".replace('.', '_').replace('/', '_')\n",
    "            file_path = os.path.join(output_dir, f\"{safe_name}.png\")\n",
    "            plt.savefig(file_path, dpi=300)\n",
    "            plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "337ccf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"eda_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for name, df in tables_dict.items():\n",
    "    df.describe(include='all').to_csv(f\"{output_dir}/{name}_describe.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
